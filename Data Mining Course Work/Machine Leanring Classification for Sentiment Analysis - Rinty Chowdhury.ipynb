{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC495 - DataMining - HW#4 - Rinty Chowdhury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data and taking sample data from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(1000000000)\n",
    "data = pd.read_csv('./1600000.processed.noemoticon.csv', names=['polarity', 'id', 'date', 'query', 'user', 'text'],\n",
    "                  encoding=\"iso-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data = data.loc[data['polarity'] == 0]\n",
    "pos_data = data.loc[data['polarity'] == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_data_sample = neg_data.sample(n = 16000)\n",
    "pos_data_sample = pos_data.sample(n = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [neg_data_sample, pos_data_sample]\n",
    "tweet = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data by removing urls, stopwords, tokenization, stemming, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    tweet_out = re.sub(r'@[A-Za-z0-9]+','',text)\n",
    "    tweet_new = re.sub(r'http://[A-Za-z0-9./]+','',tweet_out)\n",
    "    return tweet_new\n",
    "tweet['noUrl'] = tweet['text'].apply(lambda x: remove_url(x))\n",
    "def remove_punc(text):\n",
    "    text_out = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text_out\n",
    "tweet['nopunc'] = tweet['noUrl'].apply(lambda x: remove_punc(x))\n",
    "def tokanization(text):\n",
    "    tokens = re.split('\\W+', text)\n",
    "    return tokens\n",
    "tweet['tokens'] = tweet['nopunc'].apply(lambda x: tokanization(x.lower()))\n",
    "ps = nltk.PorterStemmer()\n",
    "def stemming(text):\n",
    "    out_text = [ps.stem(word) for word in text]\n",
    "    return out_text\n",
    "tweet['stemdata'] = tweet['tokens'].apply(lambda x: stemming(x))\n",
    "nltk.download('stopwords')\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    text_out = [word for word in text if word not in stopword]\n",
    "    return text_out\n",
    "tweet['tweet2'] = tweet['stemdata'].apply(lambda x: remove_stopwords(x))\n",
    "flat_list = list(itertools.chain.from_iterable(tweet['tweet2']))\n",
    "fd = nltk.FreqDist(flat_list)\n",
    "word_toKeep = list(filter(lambda x: 2000>x[1]>3, fd.items()))\n",
    "word_list_toKeep = [item[0] for item in word_toKeep]\n",
    "def remove_nonfreq(text):\n",
    "    text_out = [word for word in text if word in word_list_toKeep]\n",
    "    return text_out\n",
    "tweet['tweet3'] = tweet['tweet2'].apply(lambda x: remove_nonfreq(x))\n",
    "uniText = set(list(itertools.chain.from_iterable(tweet['tweet3'])))\n",
    "def join_tokens(tokens):\n",
    "    document = \" \".join([word for word in tokens if not word.isdigit()])\n",
    "    return document\n",
    "tweet['thirdDoc'] = tweet['tweet3'].apply(lambda x: join_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(uniText)\n",
    "countvec = cv.fit_transform(tweet['thirdDoc'])\n",
    "countvecDF = pd.DataFrame(countvec.toarray())\n",
    "countvecDF.columns = cv.get_feature_names()\n",
    "X = countvecDF\n",
    "y = tweet['polarity']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74      3196\n",
      "           4       0.73      0.76      0.75      3204\n",
      "\n",
      "    accuracy                           0.74      6400\n",
      "   macro avg       0.74      0.74      0.74      6400\n",
      "weighted avg       0.74      0.74      0.74      6400\n",
      "\n",
      "Accuracy:  0.74359375\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression = LogisticRegression()\n",
    "loreg = LogisticRegression.fit(X_train, y_train)\n",
    "y_pred = LogisticRegression.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \" , metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision score: 0.74\n",
    "## Recall score: 0.74\n",
    "## F-1 score: 0.74\n",
    "\n",
    "### Precision score of negative tweet is 0.75 and positive tweet is 0.73. It means the model is 75% correct for negative tweet and 73% correct for positive tweet over total predicted sentiment. Recall score of negative tweet is 0.72 and positive tweet is 0.76. It means the model is 72% correct for negative tweet and 76% coreect for positive tweet over the total correct predicted sentiment. F1-score is 0.74 for negative tweet and 0.75 for positive tweet. There are not significant difference between negative and positive tweet result for the model. As a result, the accuracy of the model for all tweet is 74%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
